<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cross-Validation and Training Concepts</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.9.1/chart.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; color: white; overflow-x: hidden; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { text-align: center; margin-bottom: 40px; animation: fadeInDown 1s ease-out; }
        .header h1 { font-size: 3rem; margin-bottom: 10px; background: linear-gradient(45deg, #fff, #e0e7ff); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; }
        .header p { font-size: 1.2rem; opacity: 0.9; }
        .section { background: rgba(255, 255, 255, 0.1); backdrop-filter: blur(10px); border-radius: 20px; padding: 30px; margin-bottom: 30px; border: 1px solid rgba(255, 255, 255, 0.2); animation: fadeInUp 1s ease-out; transition: transform 0.3s ease, box-shadow 0.3s ease; }
        .section:hover { transform: translateY(-5px); box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3); }
        .section h2 { font-size: 2rem; margin-bottom: 20px; color: #e0e7ff; display: flex; align-items: center; gap: 15px; }
        .icon { width: 40px; height: 40px; background: linear-gradient(45deg, #ff6b6b, #feca57); border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; font-size: 1.2rem; }
        .train-test-visual { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }
        .dataset-box { background: rgba(255, 255, 255, 0.1); border-radius: 15px; padding: 20px; text-align: center; border: 2px solid; transition: transform 0.3s ease; }
        .dataset-box:hover { transform: scale(1.05); }
        .training-set { border-color: #4ecdc4; background: linear-gradient(135deg, rgba(78, 205, 196, 0.2), rgba(78, 205, 196, 0.1)); }
        .validation-set { border-color: #feca57; background: linear-gradient(135deg, rgba(254, 202, 87, 0.2), rgba(254, 202, 87, 0.1)); }
        .test-set { border-color: #ff6b6b; background: linear-gradient(135deg, rgba(255, 107, 107, 0.2), rgba(255, 107, 107, 0.1)); }
        .cv-demo { background: rgba(255, 255, 255, 0.05); border-radius: 15px; padding: 25px; margin: 20px 0; }
        .fold-container { display: flex; flex-wrap: wrap; gap: 10px; margin: 20px 0; justify-content: center; }
        .fold { width: 60px; height: 40px; border-radius: 8px; display: flex; align-items: center; justify-content: center; font-size: 0.8rem; font-weight: bold; transition: all 0.3s ease; cursor: pointer; }
        .fold.train { background: #4ecdc4; color: white; }
        .fold.validate { background: #ff6b6b; color: white; }
        .fold:hover { transform: scale(1.1); box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3); }
        .controls { display: flex; gap: 15px; justify-content: center; margin: 20px 0; flex-wrap: wrap; }
        .btn { padding: 12px 24px; border: none; border-radius: 25px; background: linear-gradient(45deg, #ff6b6b, #feca57); color: white; font-weight: bold; cursor: pointer; transition: all 0.3s ease; font-size: 1rem; }
        .btn:hover { transform: translateY(-2px); box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3); }
        .btn:active { transform: translateY(0); }
        .metrics-display { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }
        .metric-card { background: rgba(255, 255, 255, 0.1); border-radius: 15px; padding: 20px; text-align: center; border: 1px solid rgba(255, 255, 255, 0.2); }
        .metric-value { font-size: 2rem; font-weight: bold; color: #ffd93d; display: block; margin: 10px 0; }
        .chart-container { background: rgba(255, 255, 255, 0.95); border-radius: 15px; padding: 20px; margin: 20px 0; box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3); }
        .comparison-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }
        .method-card { background: rgba(255, 255, 255, 0.05); border-radius: 15px; padding: 25px; border: 1px solid rgba(255, 255, 255, 0.1); transition: all 0.3s ease; }
        .method-card:hover { background: rgba(255, 255, 255, 0.08); transform: translateY(-5px); }
        .method-card h3 { color: #ffd93d; margin-bottom: 15px; font-size: 1.5rem; }
        .pros-cons { display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-top: 15px; }
        .pros, .cons { background: rgba(255, 255, 255, 0.05); padding: 15px; border-radius: 10px; }
        .pros h4 { color: #4ecdc4; margin-bottom: 10px; }
        .cons h4 { color: #ff6b6b; margin-bottom: 10px; }
        .pros ul, .cons ul { list-style: none; padding: 0; }
        .pros li:before { content: "âœ“ "; color: #4ecdc4; font-weight: bold; }
        .cons li:before { content: "âœ— "; color: #ff6b6b; font-weight: bold; }
        .key-points { background: rgba(255, 255, 255, 0.05); border-radius: 15px; padding: 25px; margin: 20px 0; }
        .key-points ul { list-style: none; padding: 0; }
        .key-points li { padding: 10px 0; padding-left: 30px; position: relative; line-height: 1.6; }
        .key-points li:before { content: "ðŸŽ¯"; position: absolute; left: 0; top: 10px; }
        .workflow-steps { display: flex; justify-content: space-between; align-items: center; margin: 30px 0; flex-wrap: wrap; gap: 20px; }
        .step { background: rgba(255, 255, 255, 0.1); border-radius: 15px; padding: 20px; text-align: center; flex: 1; min-width: 150px; border: 2px solid rgba(255, 255, 255, 0.2); position: relative; }
        .step:not(:last-child):after { content: "â†’"; position: absolute; right: -30px; top: 50%; transform: translateY(-50%); font-size: 2rem; color: #ffd93d; }
        .step-number { background: linear-gradient(45deg, #ff6b6b, #feca57); width: 30px; height: 30px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin: 0 auto 10px; font-weight: bold; }
        @keyframes fadeInDown { from { opacity: 0; transform: translateY(-30px);} to { opacity: 1; transform: translateY(0);} }
        @keyframes fadeInUp { from { opacity: 0; transform: translateY(30px);} to { opacity: 1; transform: translateY(0);} }
        .interactive-demo { background: rgba(255, 255, 255, 0.05); border-radius: 15px; padding: 25px; margin: 20px 0; border: 1px solid rgba(255, 255, 255, 0.1); }
        @media (max-width: 768px) {
            .header h1 { font-size: 2rem; }
            .section h2 { font-size: 1.5rem; }
            .workflow-steps { flex-direction: column; }
            .step:not(:last-child):after { content: "â†“"; right: 50%; transform: translateX(50%); top: 100%; bottom: -30px; }
            .fold-container { gap: 5px; }
            .fold { width: 40px; height: 30px; font-size: 0.7rem; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Cross-Validation & Training Concepts</h1>
            <p>Essential techniques for robust machine learning model evaluation</p>
        </div>

        <div class="section">
            <h2><span class="icon">ðŸŽ¯</span>Training, Validation & Test Sets</h2>
            <p style="font-size: 1.1rem; line-height: 1.6; margin-bottom: 20px;">
                Understanding how to properly split your data is crucial for building reliable machine learning models that generalize well to unseen data.
            </p>
            
            <div class="train-test-visual">
                <div class="dataset-box training-set">
                    <h3>Training Set (60-70%)</h3>
                    <div style="font-size: 3rem; margin: 15px 0;">ðŸ“š</div>
                    <p><strong>Purpose:</strong> Train the model parameters</p>
                    <p><strong>Usage:</strong> Model learns patterns from this data</p>
                    <p><strong>Size:</strong> Largest portion of your dataset</p>
                </div>

                <div class="dataset-box validation-set">
                    <h3>Validation Set (15-20%)</h3>
                    <div style="font-size: 3rem; margin: 15px 0;">ðŸ”§</div>
                    <p><strong>Purpose:</strong> Tune hyperparameters & model selection</p>
                    <p><strong>Usage:</strong> Evaluate different model configurations</p>
                    <p><strong>Size:</strong> Medium portion for reliable estimates</p>
                </div>

                <div class="dataset-box test-set">
                    <h3>Test Set (15-20%)</h3>
                    <div style="font-size: 3rem; margin: 15px 0;">ðŸŽ¯</div>
                    <p><strong>Purpose:</strong> Final unbiased performance evaluation</p>
                    <p><strong>Usage:</strong> Used only once at the end</p>
                    <p><strong>Size:</strong> Sufficient for reliable performance estimate</p>
                </div>
            </div>

            <div class="key-points">
                <h3>Key Principles:</h3>
                <ul>
                    <li><strong>No Data Leakage:</strong> Test set should never be used during training or validation</li>
                    <li><strong>Representative Splits:</strong> Each set should represent the overall data distribution</li>
                    <li><strong>Stratification:</strong> Maintain class balance across splits for classification problems</li>
                    <li><strong>Time Awareness:</strong> For time series data, respect temporal order in splits</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <h2><span class="icon">ðŸ”„</span>Cross-Validation Methods</h2>
            
            <div class="comparison-grid">
                <div class="method-card">
                    <h3>K-Fold Cross-Validation</h3>
                    <p>Divides data into k equal folds. Each fold serves as validation set once while others train the model.</p>
                    <div class="pros-cons">
                        <div class="pros">
                            <h4>Pros</h4>
                            <ul>
                                <li>Uses all data for both training and validation</li>
                                <li>Reduces variance in performance estimates</li>
                                <li>Standard and widely accepted</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h4>Cons</h4>
                            <ul>
                                <li>Computationally expensive (k times more training)</li>
                                <li>May not preserve class distribution</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>Stratified K-Fold</h3>
                    <p>Similar to K-Fold but maintains the class distribution in each fold, crucial for imbalanced datasets.</p>
                    <div class="pros-cons">
                        <div class="pros">
                            <h4>Pros</h4>
                            <ul>
                                <li>Preserves class distribution</li>
                                <li>Better for imbalanced datasets</li>
                                <li>More reliable performance estimates</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h4>Cons</h4>
                            <ul>
                                <li>Only applicable to classification</li>
                                <li>Still computationally expensive</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>Leave-One-Out (LOO)</h3>
                    <p>Extreme case where k equals the number of samples. Each sample is used as validation set once.</p>
                    <div class="pros-cons">
                        <div class="pros">
                            <h4>Pros</h4>
                            <ul>
                                <li>Uses maximum data for training</li>
                                <li>Deterministic results</li>
                                <li>Good for small datasets</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h4>Cons</h4>
                            <ul>
                                <li>Extremely computationally expensive</li>
                                <li>High variance in estimates</li>
                                <li>Impractical for large datasets</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>Time Series Split</h3>
                    <p>Respects temporal order by using past data for training and future data for validation.</p>
                    <div class="pros-cons">
                        <div class="pros">
                            <h4>Pros</h4>
                            <ul>
                                <li>Respects temporal dependencies</li>
                                <li>Mimics real-world deployment</li>
                                <li>Prevents data leakage from future</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h4>Cons</h4>
                            <ul>
                                <li>Only for time series data</li>
                                <li>Less data for early folds</li>
                                <li>May be affected by trends</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        

        <div class="section">
            <h2><span class="icon">âš¡</span>Training Process Workflow</h2>
            <div class="workflow-steps">
                <div class="step"><div class="step-number">1</div><h4>Data Collection</h4><p>Gather and clean your dataset</p></div>
                <div class="step"><div class="step-number">2</div><h4>Data Splitting</h4><p>Divide into train/val/test sets</p></div>
                <div class="step"><div class="step-number">3</div><h4>Cross-Validation</h4><p>Apply CV strategy on train+val</p></div>
                <div class="step"><div class="step-number">4</div><h4>Model Training</h4><p>Train models on each fold</p></div>
                <div class="step"><div class="step-number">5</div><h4>Hyperparameter Tuning</h4><p>Optimize based on CV results</p></div>
                <div class="step"><div class="step-number">6</div><h4>Final Evaluation</h4><p>Test best model on test set</p></div>
            </div>
        </div>

        <div class="section">
            <h2><span class="icon">ðŸ“Š</span>Bias-Variance Trade-off in Cross-Validation</h2>

            <div class="key-points">
                <h3>Understanding the Trade-off:</h3>
                <ul>
                    <li><strong>More Folds (Higher k):</strong> Lower bias, higher variance in performance estimates</li>
                    <li><strong>Fewer Folds (Lower k):</strong> Higher bias, lower variance in performance estimates</li>
                    <li><strong>Sweet Spot:</strong> 5-10 folds typically provide good balance for most problems</li>
                    <li><strong>Computational Cost:</strong> More folds mean more model training iterations</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <h2><span class="icon">ðŸ’¡</span>Best Practices & Key Takeaways</h2>
            <div class="key-points">
                <ul>
                    <li><strong>Choose Appropriate CV:</strong> Consider your data type (time series, imbalanced, small datasets)</li>
                    <li><strong>Consistent Preprocessing:</strong> Apply the same preprocessing to all folds</li>
                    <li><strong>Avoid Data Leakage:</strong> Never use future information to predict the past</li>
                    <li><strong>Report Statistics:</strong> Always report mean and standard deviation of CV scores</li>
                    <li><strong>Stratify When Needed:</strong> Use stratified sampling for classification problems</li>
                    <li><strong>Nested CV:</strong> Use nested cross-validation for unbiased model comparison</li>
                    <li><strong>Save Your Models:</strong> Keep trained models from each fold for ensembling</li>
                    <li><strong>Monitor Overfitting:</strong> Large gap between training and validation scores indicates overfitting</li>
                </ul>
            </div>
        </div>
    </div>

    <script>
        let currentK = 5;
        let currentFoldIndex = 0;
        let animationInterval;
        let cvChart, biasVarianceChart;

        function setKFolds(k) {
            currentK = k;
            currentFoldIndex = 0;
            generateFolds();
            updateMetrics();
            updateCVChart();
        }

        function generateFolds() {
            const container = document.getElementById('foldVisualization');
            container.innerHTML = '';
            for (let i = 0; i < currentK; i++) {
                const fold = document.createElement('div');
                fold.className = 'fold';
                fold.textContent = i + 1;
                fold.onclick = () => setCurrentFold(i);
                container.appendChild(fold);
            }
            setCurrentFold(currentFoldIndex);
        }

        function setCurrentFold(foldIndex) {
            currentFoldIndex = foldIndex;
            const folds = document.querySelectorAll('.fold');
            folds.forEach((fold, index) => {
                fold.className = 'fold';
                if (index === foldIndex) { fold.classList.add('validate'); }
                else { fold.classList.add('train'); }
            });
            updateMetrics();
        }

        function updateMetrics() {
            document.getElementById('currentFold').textContent = currentFoldIndex + 1;
            document.getElementById('trainingSamples').textContent = currentK - 1;
            document.getElementById('validationSamples').textContent = 1;
            document.getElementById('dataUtilization').textContent = '100%';
        }

        function animateFolds() {
            if (animationInterval) { clearInterval(animationInterval); animationInterval = null; return; }
            let fold = 0;
            animationInterval = setInterval(() => {
                setCurrentFold(fold);
                fold = (fold + 1) % currentK;
            }, 1500);
        }

        function initCVChart() {
            const ctx = document.getElementById('cvChart').getContext('2d');
            const kValues = [2, 3, 4, 5, 6, 7, 8, 9, 10];
            const accuracyMeans = [0.82, 0.84, 0.85, 0.86, 0.857, 0.855, 0.853, 0.851, 0.85];
            const accuracyStds = [0.08, 0.06, 0.05, 0.04, 0.038, 0.042, 0.045, 0.048, 0.05];
            cvChart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: kValues,
                    datasets: [{
                        label: 'Mean CV Accuracy',
                        data: accuracyMeans,
                        borderColor: '#4ecdc4',
                        backgroundColor: 'rgba(78, 205, 196, 0.1)',
                        borderWidth: 3,
                        fill: false
                    }, {
                        label: 'CV Standard Deviation',
                        data: accuracyStds,
                        borderColor: '#ff6b6b',
                        backgroundColor: 'rgba(255, 107, 107, 0.1)',
                        borderWidth: 3,
                        fill: false,
                        yAxisID: 'y1'
                    }]
                },
                options: {
                    responsive: true,
                    plugins: {
                        title: { display: true, text: 'Cross-Validation Performance vs Number of Folds', color: '#333', font: { size: 16, weight: 'bold' } },
                        legend: { labels: { color: '#333' } }
                    },
                    scales: {
                        x: { title: { display: true, text: 'Number of Folds (k)', color: '#333' }, ticks: { color: '#333' } },
                        y: { type: 'linear', position: 'left', title: { display: true, text: 'Mean Accuracy', color: '#333' }, ticks: { color: '#333' } },
                        y1: { type: 'linear', position: 'right', title: { display: true, text: 'Standard Deviation', color: '#333' }, ticks: { color: '#333' }, grid: { drawOnChartArea: false } }
                    }
                }
            });
        }

        function updateCVChart() { if (cvChart) { cvChart.update(); } }

        function initBiasVarianceChart() {
            const ctx = document.getElementById('biasVarianceChart').getContext('2d');
            const kValues = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20];
            const bias = [0.15, 0.12, 0.10, 0.08, 0.07, 0.065, 0.06, 0.058, 0.055, 0.05, 0.048];
            const variance = [0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06, 0.08, 0.10];
            const totalError = bias.map((b, i) => b + variance[i]);
            biasVarianceChart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: kValues,
                    datasets: [{
                        label: 'BiasÂ²',
                        data: bias,
                        borderColor: '#ff6b6b',
                        backgroundColor: 'rgba(255, 107, 107, 0.1)',
                        borderWidth: 3,
                        fill: false
                    }, {
                        label: 'Variance',
                        data: variance,
                        borderColor: '#4ecdc4',
                        backgroundColor: 'rgba(78, 205, 196, 0.1)',
                        borderWidth: 3,
                        fill: false
                    }, {
                        label: 'Total Error',
                        data: totalError,
                        borderColor: '#feca57',
                        backgroundColor: 'rgba(254, 202, 87, 0.1)',
                        borderWidth: 3,
                        fill: false
                    }]
                },
                options: {
                    responsive: true,
                    plugins: {
                        title: { display: true, text: 'Bias-Variance Trade-off in Cross-Validation', color: '#333', font: { size: 16, weight: 'bold' } },
                        legend: { labels: { color: '#333' } }
                    },
                    scales: {
                        x: { title: { display: true, text: 'Number of Folds (k)', color: '#333' }, ticks: { color: '#333' } },
                        y: { title: { display: true, text: 'Error', color: '#333' }, ticks: { color: '#333' } }
                    }
                }
            });
        }

        document.addEventListener('DOMContentLoaded', function() {
            setKFolds(5);
            initCVChart();
            initBiasVarianceChart();
        });
    </script>
</body>
</html>
