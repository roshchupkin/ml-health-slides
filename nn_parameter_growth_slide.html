<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Parameter Growth</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.2);
        }
        
        h1 {
            text-align: center;
            color: #2d3748;
            margin-bottom: 10px;
            font-size: 2.2em;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }
        
        .controls-section {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 30px;
        }
        
        .control-group {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 15px;
            border: 2px solid #e2e8f0;
        }
        
        .control-group h3 {
            color: #2d3748;
            margin-bottom: 15px;
            font-size: 1.3em;
            display: flex;
            align-items: center;
        }
        
        .icon {
            margin-right: 10px;
            font-size: 1.5em;
        }
        
        .control {
            margin-bottom: 15px;
        }
        
        label {
            display: block;
            margin-bottom: 5px;
            color: #4a5568;
            font-weight: 600;
        }
        
        input[type="range"] {
            width: 100%;
            height: 8px;
            border-radius: 4px;
            background: #e2e8f0;
            outline: none;
            -webkit-appearance: none;
        }
        
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: linear-gradient(45deg, #667eea, #764ba2);
            cursor: pointer;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.2);
        }
        
        .value-display {
            display: inline-block;
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 4px 12px;
            border-radius: 15px;
            font-weight: bold;
            margin-left: 10px;
        }
        
        .results-section {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 30px;
        }
        
        .result-card {
            background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
            padding: 25px;
            border-radius: 15px;
            border: 2px solid #e2e8f0;
            text-align: center;
            transition: all 0.3s ease;
        }
        
        .result-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
        }
        
        .result-card h3 {
            color: #2d3748;
            margin-bottom: 15px;
            font-size: 1.4em;
        }
        
        .parameter-count {
            font-size: 2.5em;
            font-weight: bold;
            margin: 15px 0;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        
        .parameter-details {
            background: #f1f5f9;
            padding: 15px;
            border-radius: 10px;
            margin-top: 15px;
            font-size: 0.9em;
            color: #64748b;
        }
        
        .comparison-section {
            background: linear-gradient(135deg, #fef7e0 0%, #fff3cd 100%);
            padding: 25px;
            border-radius: 15px;
            border: 2px solid #fbbf24;
            margin-bottom: 20px;
        }
        
        .comparison-section h3 {
            color: #92400e;
            margin-bottom: 15px;
            text-align: center;
            font-size: 1.4em;
        }
        
        .comparison-stats {
            display: grid;
            grid-template-columns: 1fr auto 1fr;
            align-items: center;
            gap: 20px;
            text-align: center;
        }
        
        .vs-symbol {
            font-size: 2em;
            font-weight: bold;
            color: #92400e;
            background: white;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            border: 3px solid #fbbf24;
        }
        
        .efficiency-note {
            background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%);
            padding: 20px;
            border-radius: 15px;
            border: 2px solid #22c55e;
            text-align: center;
            color: #166534;
            font-weight: 600;
        }
        
        .network-viz {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 20px 0;
        }
        
        .layer {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 4px;
        }
        
        .neuron {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: linear-gradient(45deg, #667eea, #764ba2);
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }
        
        .connection {
            width: 30px;
            height: 2px;
            background: linear-gradient(to right, #667eea, #764ba2);
            margin: 0 10px;
            opacity: 0.6;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Neural Network Parameter Growth</h1>
        <p class="subtitle">Interactive demonstration: Two different approaches to solve the same image classification task</p>
        
        <div class="comparison-section" style="margin-bottom: 30px;">
            <h3>üéØ Task: Image Classification</h3>
            <p style="text-align: center; margin: 10px 0; color: #666;">
                <strong>Same input:</strong> <span id="taskInput">224√ó224 RGB image</span> ‚Üí <strong>Same output:</strong> 10 classes<br>
                <strong>Different approaches:</strong> How to process the image?
            </p>
        </div>

        <div class="controls-section">
            <div class="control-group">
                <h3><span class="icon">üèóÔ∏è</span>Dense Network Design</h3>
                <div class="control">
                    <label for="layers">Number of Hidden Layers:</label>
                    <input type="range" id="layers" min="1" max="10" value="3">
                    <span class="value-display" id="layersValue">3</span>
                </div>
                <div class="control">
                    <label for="neurons">Neurons per Hidden Layer:</label>
                    <input type="range" id="neurons" min="64" max="1024" step="64" value="256">
                    <span class="value-display" id="neuronsValue">256</span>
                </div>
            </div>
            
            <div class="control-group">
                <h3><span class="icon">üñºÔ∏è</span>Input Image (Both Networks)</h3>
                <div class="control">
                    <label for="imageSize">Image Size (width = height):</label>
                    <input type="range" id="imageSize" min="64" max="512" step="32" value="224">
                    <span class="value-display" id="imageSizeValue">224</span>
                </div>
                <div class="control">
                    <label for="channels">Color Channels:</label>
                    <input type="range" id="channels" min="1" max="3" value="3">
                    <span class="value-display" id="channelsValue">3 (RGB)</span>
                </div>
            </div>
        </div>
        
        <div class="results-section">
            <div class="result-card">
                <h3>üß† Approach 1: Dense Neural Network</h3>
                <p style="color: #666; font-size: 0.9em; margin-bottom: 10px;">Flatten image ‚Üí Connect every pixel to every neuron</p>
                <div class="parameter-count" id="denseParams">Loading...</div>
                <div class="parameter-details" id="denseDetails">
                    Input size: <span id="inputSize">-</span><br>
                    Total connections: <span id="connections">-</span>
                </div>
            </div>
            
            <div class="result-card">
                <h3>üîç Approach 2: Convolutional Neural Network</h3>
                <p style="color: #666; font-size: 0.9em; margin-bottom: 10px;">Use local filters ‚Üí Shared weights ‚Üí Dense classification</p>
                <div class="parameter-count" id="cnnParams">Loading...</div>
                <div class="parameter-details" id="cnnDetails">
                    Conv layers: 3√ó3 kernels, 32‚Üí64‚Üí128 filters<br>
                    Max pooling after each conv layer<br>
                    Adaptive dense layer based on feature count<br>
                    Final dense: <span id="finalDense">-</span>
                </div>
            </div>
        </div>
        
        <div class="comparison-section">
            <h3>üìä Efficiency Comparison</h3>
            <div class="comparison-stats">
                <div>
                    <strong>Dense Network</strong><br>
                    <span id="denseRatio" style="font-size: 1.5em; color: #dc2626;">-</span>
                </div>
                <div class="vs-symbol">VS</div>
                <div>
                    <strong>CNN</strong><br>
                    <span id="cnnRatio" style="font-size: 1.5em; color: #16a34a;">1.0√ó</span>
                </div>
            </div>
        </div>
        
        <div class="efficiency-note" id="efficiencyNote">
            üéØ CNNs are incredibly parameter-efficient for image processing!<br>
            <small>Dense networks connect every input pixel to every neuron, while CNNs use shared weights and local receptive fields.</small>
        </div>
    </div>

    <script>
        // Get all input elements
        const layersSlider = document.getElementById('layers');
        const neuronsSlider = document.getElementById('neurons');
        const imageSizeSlider = document.getElementById('imageSize');
        const channelsSlider = document.getElementById('channels');
        
        // Get all display elements
        const layersValue = document.getElementById('layersValue');
        const neuronsValue = document.getElementById('neuronsValue');
        const imageSizeValue = document.getElementById('imageSizeValue');
        const channelsValue = document.getElementById('channelsValue');
        
        // Get result elements
        const denseParams = document.getElementById('denseParams');
        const cnnParams = document.getElementById('cnnParams');
        const denseDetails = document.getElementById('denseDetails');
        const cnnDetails = document.getElementById('cnnDetails');
        const inputSize = document.getElementById('inputSize');
        const connections = document.getElementById('connections');
        const finalDense = document.getElementById('finalDense');
        const denseRatio = document.getElementById('denseRatio');
        const efficiencyNote = document.getElementById('efficiencyNote');
        
        function formatNumber(num) {
            if (num >= 1e9) {
                return (num / 1e9).toFixed(2) + 'B';
            } else if (num >= 1e6) {
                return (num / 1e6).toFixed(2) + 'M';
            } else if (num >= 1e3) {
                return (num / 1e3).toFixed(1) + 'K';
            }
            return num.toLocaleString();
        }
        
        function updateChannelDisplay(value) {
            const channelNames = ['1 (Grayscale)', '2 (GA)', '3 (RGB)'];
            return channelNames[value - 1] || value;
        }
        
        function calculateParameters() {
            const layers = parseInt(layersSlider.value);
            const neuronsPerLayer = parseInt(neuronsSlider.value);
            const imageSize = parseInt(imageSizeSlider.value);
            const channels = parseInt(channelsSlider.value);
            
            // Update display values
            layersValue.textContent = layers;
            neuronsValue.textContent = neuronsPerLayer;
            imageSizeValue.textContent = imageSize + '√ó' + imageSize;
            channelsValue.textContent = updateChannelDisplay(channels);
            
            // Update task input display
            document.getElementById('taskInput').textContent = imageSize + '√ó' + imageSize + ' ' + updateChannelDisplay(channels).toLowerCase();
            
            // Calculate Dense Network Parameters
            const inputDims = imageSize * imageSize * channels;
            let denseParamCount = 0;
            let prevLayerSize = inputDims;
            
            // Hidden layers
            for (let i = 0; i < layers; i++) {
                denseParamCount += prevLayerSize * neuronsPerLayer + neuronsPerLayer; // weights + biases
                prevLayerSize = neuronsPerLayer;
            }
            
            // Output layer (assuming 10 classes)
            const outputClasses = 10;
            denseParamCount += prevLayerSize * outputClasses + outputClasses;
            
            // Calculate CNN Parameters (efficient architecture)
            let cnnParamCount = 0;
            
            // Conv Layer 1: 3x3xchannels -> 32 filters
            cnnParamCount += 3 * 3 * channels * 32 + 32;
            
            // Conv Layer 2: 3x3x32 -> 64 filters  
            cnnParamCount += 3 * 3 * 32 * 64 + 64;
            
            // Conv Layer 3: 3x3x64 -> 128 filters
            cnnParamCount += 3 * 3 * 64 * 128 + 128;
            
            // Calculate final feature map size after 3 conv layers with max pooling
            // Each conv layer: size remains same (with padding='same')
            // Each pooling layer: size reduces by factor of 2
            let currentSize = imageSize;
            currentSize = Math.floor(currentSize / 2); // Pooling after conv1
            currentSize = Math.floor(currentSize / 2); // Pooling after conv2  
            currentSize = Math.floor(currentSize / 2); // Pooling after conv3
            const finalFeatures = currentSize * currentSize * 128;
            
            // Adaptive dense layer size based on feature count
            let denseLayerSize = Math.min(128, Math.max(64, Math.floor(finalFeatures / 4)));
            
            // Dense layer: features -> adaptive size
            cnnParamCount += finalFeatures * denseLayerSize + denseLayerSize;
            
            // Output layer: adaptive size -> 10 classes
            cnnParamCount += denseLayerSize * outputClasses + outputClasses;
            
            // Update displays
            denseParams.textContent = formatNumber(denseParamCount);
            cnnParams.textContent = formatNumber(cnnParamCount);
            
            inputSize.textContent = formatNumber(inputDims);
            connections.textContent = formatNumber(denseParamCount);
            finalDense.textContent = formatNumber(finalFeatures) + ' ‚Üí ' + denseLayerSize + ' ‚Üí 10';
            
            // Calculate ratio
            const ratio = denseParamCount / cnnParamCount;
            denseRatio.textContent = ratio.toFixed(1) + '√ó';
            
            // Update efficiency note
            if (ratio > 100) {
                efficiencyNote.innerHTML = 'üö® Dense network has ' + ratio.toFixed(0) + '√ó more parameters! CNNs are incredibly efficient for images.';
                efficiencyNote.style.background = 'linear-gradient(135deg, #fee2e2 0%, #fecaca 100%)';
                efficiencyNote.style.borderColor = '#ef4444';
                efficiencyNote.style.color = '#991b1b';
            } else if (ratio > 10) {
                efficiencyNote.innerHTML = '‚ö†Ô∏è Dense network has ' + ratio.toFixed(1) + '√ó more parameters. CNNs show clear advantage!';
                efficiencyNote.style.background = 'linear-gradient(135deg, #fef7e0 0%, #fff3cd 100%)';
                efficiencyNote.style.borderColor = '#fbbf24';
                efficiencyNote.style.color = '#92400e';
            } else {
                efficiencyNote.innerHTML = '‚úÖ CNNs maintain efficiency even with larger networks!';
                efficiencyNote.style.background = 'linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%)';
                efficiencyNote.style.borderColor = '#22c55e';
                efficiencyNote.style.color = '#166534';
            }
        }
        
        // Add event listeners
        layersSlider.addEventListener('input', calculateParameters);
        neuronsSlider.addEventListener('input', calculateParameters);
        imageSizeSlider.addEventListener('input', calculateParameters);
        channelsSlider.addEventListener('input', calculateParameters);
        
        // Initial calculation
        calculateParameters();
    </script>
</body>
</html>